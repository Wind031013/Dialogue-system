{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac607286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\wind\\AppData\\Local\\Temp\\ipykernel_16692\\3790243778.py:7: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  jieba.load_userdict('E:\\论文\\代码\\数据处理\\my_dict.txt')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import jieba \n",
    "import jieba.posseg as pseg\n",
    "\n",
    "jieba.load_userdict('E:\\论文\\代码\\数据处理\\my_dict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69e54de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据文件\n",
    "def readData(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return []\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "036f88ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取数据文件数量\n",
    "def get_file_count(directory_path):\n",
    "    try:\n",
    "        file_count = 0\n",
    "        with os.scandir(directory_path) as entries:\n",
    "            for entry in entries:\n",
    "                if entry.is_file():\n",
    "                    file_count += 1\n",
    "        return file_count\n",
    "    except FileNotFoundError:\n",
    "        print(f\"目录不存在: {directory_path}\")\n",
    "        return 0\n",
    "    except PermissionError:\n",
    "        print(f\"没有权限访问目录: {directory_path}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a99c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 情绪字典\n",
    "def is_emotion_word(word):\n",
    "    emotion_words = {\n",
    "        '高兴', '快乐', '开心', '愉快', '兴奋', '激动', '幸福',\n",
    "        '悲伤', '难过', '伤心', '痛苦', '悲哀', '沮丧', '失望',\n",
    "        '愤怒', '生气', '气愤', '恼怒', '暴躁', '愤怒',\n",
    "        '害怕', '恐惧', '惊恐', '慌张', '紧张', '焦虑',\n",
    "        '惊讶', '惊奇', '吃惊', '意外', '震惊',\n",
    "        '讨厌', '厌恶', '反感', '憎恶', '嫌弃',\n",
    "        '喜欢', '爱', '欣赏', '迷恋', '陶醉'\n",
    "    }\n",
    "    return word in emotion_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f3365bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到对话中的人名以及形容词\n",
    "def find_name_adjective(dialogue):\n",
    "    text_without_quotes = re.sub(r'\"[^\"]*', '', dialogue)\n",
    "    words = pseg.cut(text_without_quotes)\n",
    "    person_flags = {'nr', 'nrt'}\n",
    "    adjective_flags = {'a'}\n",
    "    persons = []\n",
    "    adjectives = []\n",
    "    for word, flag in words:\n",
    "        if flag in person_flags:\n",
    "            persons.append(word)\n",
    "        elif flag in adjective_flags and is_emotion_word(word):\n",
    "            adjectives.append(word)\n",
    "    return persons, adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d34c2291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_TangSan_dialogues(line):\n",
    "    train_data = []\n",
    "    patterns = [\n",
    "        r'.*?[\"“](.*?)[\"”]',\n",
    "        # r'唐三.*?[\"“](.*?)[\"”]',\n",
    "        # r'^(?!.*唐三.*[\"“].*[\"”]).*[\"“](.*?)[\"”](?!唐三)'\n",
    "    ]\n",
    "    dialogues = re.findall(patterns[0], line)\n",
    "    if dialogues:\n",
    "        persons, adjectives = find_name_adjective(line)\n",
    "        train_data.append({\n",
    "            'character': persons,\n",
    "            'emotion': adjectives,\n",
    "            'dialogue': dialogues\n",
    "        })\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "718b2278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_conversation_format(data, output_path):\n",
    "    formatted_data = []\n",
    "    for i in range(1, len(data)):\n",
    "        item = data[i]\n",
    "        last_speak_character = data[i]['character']\n",
    "        # 构建对话上下文\n",
    "        personSystem = \"你是唐三，前世为唐门外门弟子，因偷学内门绝技《玄天宝录》而自杀谢罪，穿越至斗罗大陆。你是万年不遇的双生武魂拥有者（昊天锤、蓝银皇），未来的海神与修罗神双神位继承者。你性格沉稳坚毅、睿智冷静、极其重情重义，尤其深爱小舞，愿为她付出一切。你秉持‘人不犯我，我不犯人；人若犯我，步步逼人’的准则。你精通唐门绝学（玄玉手、紫极魔瞳、暗器百解等），擅长在战斗中使用智慧和技巧。\"\n",
    "        # 如果姓名列表内有唐三两字且出现的频率是最高的才创建对话格式\n",
    "        if '唐三' in item['character']:\n",
    "            # 创建对话格式\n",
    "            messages = {\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                    \"system\": personSystem,\n",
    "                    \"input\": data[i - 1]['dialogue'][0],\n",
    "                    \"output\": data[i]['dialogue'][0]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            # 如果上一次说话的人也是唐三则把新的一段对话合并\n",
    "            if last_speak_character and '唐三' in last_speak_character:\n",
    "                formatted_data[-1]['messages'][0]['output'] += \" \" + messages['messages'][0]['output']\n",
    "            else:\n",
    "                formatted_data.append(messages)\n",
    "\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(formatted_data, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"对话格式数据已导出到: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca62606f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[32m     11\u001b[39m         train_data.extend(extract_TangSan_dialogues(line))\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mexport_to_conversation_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconversations.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 打印前几条数据作为示例\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m前3条数据示例:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mexport_to_conversation_format\u001b[39m\u001b[34m(data, output_path)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# 如果上一次说话的人也是唐三则把新的一段对话合并\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m last_speak_character \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m唐三\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m last_speak_character:\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[43mformatted_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m'\u001b[39m] += \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m + messages[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     24\u001b[39m     formatted_data.append(messages)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_data = []\n",
    "    train_data_path = r\"E:\\论文\\代码\\数据处理\\NonEmptyData\"\n",
    "    output_path = r\"E:\\论文\\代码\\数据处理\\output\"\n",
    "    #获取文件数量\n",
    "    file_count = get_file_count(train_data_path)\n",
    "    for i in range(1, file_count + 1):\n",
    "        file_path = os.path.join(train_data_path, f\"train_{i}.txt\")\n",
    "        lines = readData(file_path)\n",
    "        for line in lines:\n",
    "            train_data.extend(extract_TangSan_dialogues(line))\n",
    "    export_to_conversation_format(train_data, os.path.join(output_path, \"conversations.json\"))\n",
    "    \n",
    "    # 打印前几条数据作为示例\n",
    "    print(\"\\n前3条数据示例:\")\n",
    "    for i, item in enumerate(train_data[:3]):\n",
    "        print(f\"数据 {i+1}:\")\n",
    "        print(f\"  人物: {item['character']}\")\n",
    "        print(f\"  情感词: {item['emotion']}\")\n",
    "        print(f\"  对话: {item['dialogue']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
